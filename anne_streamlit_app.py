import streamlit as st
from langchain_community.vectorstores.supabase import SupabaseVectorStore
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain
from langchain.prompts import PromptTemplate
from langchain.schema import HumanMessage, SystemMessage
from supabase import create_client
import os
from dotenv import load_dotenv

# PWA ê´€ë ¨ HTML ì½”ë“œ ì¶”ê°€
st.set_page_config(
    page_title="ì•¤ ì…œë¦¬ì™€ì˜ ëŒ€í™”",
    page_icon="ğŸ‘©â€ğŸ¦°",
    layout="wide"
)

# PWA ë©”íƒ€íƒœê·¸ì™€ ë§í¬ ì¶”ê°€
st.markdown('''
    <head>
        <link rel="manifest" href="/manifest.json">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#f5f5f5">
        <link rel="icon" type="image/png" sizes="192x192" href="/assets/icon-192x192.png">
        <link rel="icon" type="image/png" sizes="512x512" href="/assets/icon-512x512.png">
        <link rel="apple-touch-icon" href="/assets/icon-192x192.png">
    </head>
''', unsafe_allow_html=True)

# Service Worker ë“±ë¡
st.markdown('''
    <script>
        if ('serviceWorker' in navigator) {
            window.addEventListener('load', function() {
                navigator.serviceWorker.register('/service-worker.js')
                    .then(function(registration) {
                        console.log('ServiceWorker registration successful');
                    })
                    .catch(function(err) {
                        console.log('ServiceWorker registration failed: ', err);
                    });
            });
        }
    </script>
''', unsafe_allow_html=True)

# ì‚¬ì´ë“œë°”ì— ì´ë¯¸ì§€ì™€ ì†Œê°œ ì¶”ê°€
with st.sidebar:
    st.image("assets/anne.jpg", width=300)
    st.title("ì•¤ ì…œë¦¬")
    st.markdown("""
    ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ê·¸ë¦°ê²Œì´ë¸”ì¦ˆì˜ ì•¤ ì…œë¦¬ì˜ˆìš”. 
    ìƒìƒë ¥ì´ í’ë¶€í•˜ê³  ìˆ˜ë‹¤ìŠ¤ëŸ¬ìš´ 13ì‚´ ì†Œë…€ëë‹ˆë‹¤.
    
    ì €ì™€ í•¨ê»˜ ì´ì•¼ê¸°í•˜ë©´ì„œ ê·¸ë¦°ê²Œì´ë¸”ì¦ˆì˜ ì•„ë¦„ë‹¤ì›€ì„ ëŠê»´ë³´ì„¸ìš”!
    
    *"ì˜¤ëŠ˜ì€ ìƒˆë¡œìš´ ë‚ ì´ì—ìš”. ì•„ì§ ì•„ë¬´ëŸ° ì‹¤ìˆ˜ë„ í•˜ì§€ ì•Šì€ ë‚ ì´ì£ !"* âœ¨
    """)

# ì´ˆê¸° ì„¤ì •
@st.cache_resource
def initialize_chain():
    try:
        # Supabase ì„¤ì •
        supabase_url = st.secrets["SUPABASE_URL"]
        supabase_key = st.secrets["SUPABASE_SERVICE_ROLE_KEY"]
        openai_api_key = st.secrets["OPENAI_API_KEY"]
        
        if not all([supabase_url, supabase_key, openai_api_key]):
            st.error("Required secrets are missing")
            st.stop()
            
        # Debug information
        st.write("Attempting to connect to Supabase...")
        
        # Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        try:
            client = create_client(supabase_url, supabase_key)
            st.write("Successfully connected to Supabase!")
        except Exception as e:
            st.error(f"Failed to create Supabase client: {str(e)}")
            st.stop()
        
        # ì„ë² ë”© ëª¨ë¸ ì„¤ì •
        embeddings = OpenAIEmbeddings(
            model="text-embedding-3-large",
            dimensions=1536,
            api_key=openai_api_key
        )
        
        # ë²¡í„° ì €ì¥ì†Œ ìƒì„±
        vectorstore = SupabaseVectorStore(
            client=client,
            embedding=embeddings,
            table_name="embeddings",
            query_name="match_embeddings"
        )
        
        # ë©”ëª¨ë¦¬ ì„¤ì •
        memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True,
            output_key="answer"
        )
        
        # LLM ëª¨ë¸ ì´ˆê¸°í™”
        llm = ChatOpenAI(
            model_name="gpt-4",
            temperature=0.7,
            api_key=openai_api_key
        )
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        QA_PROMPT = PromptTemplate.from_template("""
        ë‹¹ì‹ ì€ Lucy Maud Montgomeryì˜ ì‘í’ˆ Anne of Green Gablesì˜ ì£¼ì¸ê³µ Anne Shirleyì…ë‹ˆë‹¤. 
        ë‹¤ìŒê³¼ ê°™ì€ ì•¤ì˜ ì„±ê²©ê³¼ íŠ¹ì§•ì„ ì‚´ë ¤ ë‹µë³€í•´ì£¼ì„¸ìš”:

        1. ìƒìƒë ¥ì´ í’ë¶€í•˜ê³  ë‚­ë§Œì ì¸ ì„±ê²©:
           - ì¼ìƒì ì¸ ê²ƒë„ ì•„ë¦„ë‹µê³  ì‹œì ìœ¼ë¡œ í‘œí˜„
           - ìì—°ê³¼ ì•„ë¦„ë‹¤ì›€ì— ëŒ€í•œ ê¹Šì€ ì• ì •
           - "ì˜¤, ì •ë§ ë©‹ì§€ì§€ ì•Šì•„ìš”?"ì™€ ê°™ì€ ê°íƒ„ë¬¸ ìì£¼ ì‚¬ìš©

        2. ìˆ˜ë‹¤ìŠ¤ëŸ½ê³  ì—´ì •ì ì¸ ë§íˆ¬:
           - ê¸´ ë¬¸ì¥ê³¼ ìì„¸í•œ ì„¤ëª…ì„ ì„ í˜¸
           - ê°ì •ì„ ê°•ì¡°í•˜ëŠ” í‘œí˜„ ì‚¬ìš©
           - ë•Œë¡œëŠ” ê³ ê¸‰ ë‹¨ì–´ë‚˜ ë¬¸í•™ì  í‘œí˜„ ì‚¬ìš©

        3. ì² í•™ì ì´ê³  ì‚¬ë ¤ ê¹Šì€ ë©´ëª¨:
           - ê¹Šì´ ìˆëŠ” ìƒê°ê³¼ í†µì°°ë ¥ í‘œí˜„
           - ìì‹ ì˜ ì‹¤ìˆ˜ë‚˜ ê²½í—˜ì—ì„œ ë°°ìš´ êµí›ˆ ê³µìœ 
           - ì§„ì†”í•˜ê³  ì •ì§í•œ íƒœë„

        4. íŠ¹ì§•ì ì¸ í‘œí˜„:
           - "ìƒìƒë ¥ì„ í¼ì¹  ì—¬ì§€ê°€ ìˆì–´ìš”!"
           - "ë§ˆìŒì´ í†µí•˜ëŠ” ì‚¬ëŒì´ì—ìš”!"
           - "ì ˆë§ì˜ êµ¬ë í……ì´"
           ê°™ì€ ì•¤ì˜ ì‹œê·¸ë‹ˆì²˜ í‘œí˜„ë“¤ì„ ì ì ˆíˆ ì‚¬ìš©

        ì°¸ê³  ë‚´ìš©:
        {context}

        ì§ˆë¬¸: {question}

        ë‹µë³€:""")
        
        # ëŒ€í™”í˜• ì²´ì¸ ìƒì„±
        chain = ConversationalRetrievalChain.from_llm(
            llm=llm,
            retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
            memory=memory,
            combine_docs_chain_kwargs={'prompt': QA_PROMPT}
        )
        
        return chain
    except Exception as e:
        st.error(f"Error initializing chain: {e}")
        return None

# ì²´ì¸ ì´ˆê¸°í™”
chain = initialize_chain()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
st.title("ğŸ‘©â€ğŸ¦° ì•¤ ì…œë¦¬ì™€ì˜ ëŒ€í™”")

# ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì•¤ì—ê²Œ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ë³´ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # ì•¤ì˜ ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ì•¤ì´ ìƒê°í•˜ê³  ìˆì–´ìš”..."):
            response = chain({"question": prompt})
            st.markdown(response["answer"])
            st.session_state.messages.append({"role": "assistant", "content": response["answer"]})

# ìŠ¤íƒ€ì¼ ì ìš©
st.markdown("""
<style>
    .stApp {
        background-color: #f5f5f5;
    }
    .css-1d391kg {
        background-color: #ffffff;
    }
    .stChatMessage {
        background-color: #ffffff;
        border-radius: 15px;
        padding: 10px;
        margin: 5px 0;
    }
</style>
""", unsafe_allow_html=True) 
